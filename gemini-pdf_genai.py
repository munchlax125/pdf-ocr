import os
import re
import json
import gspread
from google.oauth2 import service_account
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

# --- âš™ï¸ 1. ì‚¬ìš©ì ì„¤ì • ---
API_KEY = os.getenv("GOOGLE_API_KEY")  # .env íŒŒì¼ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
SERVICE_ACCOUNT_FILE = 'pdf-ocr.json'
SPREADSHEET_NAME = 'pdf-ocr'
PDF_FOLDER_PATH = './pdfs/'

# --- ğŸ¤– 2. ì¶”ì¶œ í•„ë“œ ë° í”„ë¡¬í”„íŠ¸ ---
EXTRACTION_FIELDS = [
    "ì„±ëª…", "ìƒë…„ì›”ì¼", "ì•ˆë‚´ìœ í˜•", "ê¸°ì¥ì˜ë¬´", "ì¶”ê³„ì‹œ ì ìš©ê²½ë¹„ìœ¨",
    "ì†Œë“ì¢…ë¥˜", "ì´ì", "ë°°ë‹¹", "ê·¼ë¡œ-ë‹¨ì¼", "ê·¼ë¡œ-ë³µìˆ˜",
    "ì—°ê¸ˆ", "ê¸°íƒ€", "ì¢…êµì¸ ê¸°íƒ€ì†Œë“ìœ ë¬´", "ì¤‘ê°„ì˜ˆë‚©ì„¸ì•¡", "ì›ì²œì§•ìˆ˜ì„¸ì•¡",
    "êµ­ë¯¼ì—°ê¸ˆë³´í—˜ë£Œ", "ê°œì¸ì—°ê¸ˆì €ì¶•", "ì†Œê¸°ì—…ì†Œìƒê³µì¸ê³µì œë¶€ê¸ˆ (ë…¸ë€ìš°ì‚°ê³µì œ)",
    "í‡´ì§ì—°ê¸ˆì„¸ì•¡ê³µì œ", "ì—°ê¸ˆê³„ì¢Œì„¸ì•¡ê³µì œ", "ì‚¬ì—…ì ë“±ë¡ë²ˆí˜¸", "ìƒí˜¸", "ìˆ˜ì…ê¸ˆì•¡ êµ¬ë¶„ì½”ë“œ",
    "ì—…ì¢… ì½”ë“œ", "ì‚¬ì—… í˜•íƒœ", "ê¸°ì¥ ì˜ë¬´", "ê²½ë¹„ìœ¨",
    "ìˆ˜ì…ê¸ˆì•¡", "ì¼ë°˜", "ìê°€", "ì¼ë°˜(ê¸°ë³¸)", "ìê°€(ì´ˆê³¼)"
]

json_example = "[\n" + "  {\n" + ",\n".join([f'    "{field}": "ê°’"' for field in EXTRACTION_FIELDS]) + "\n  },\n  {\n" + ",\n".join([f'    "{field}": "ê°’2"' for field in EXTRACTION_FIELDS]) + "\n  }\n]"

GEMINI_PROMPT = f"""
## ì—­í• 
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ì„œ ì „ì²´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì—¬ëŸ¬ ë‹¤ë¥¸ ìœ„ì¹˜ì™€ í˜•ì‹ì˜ í‘œë‚˜ í…ìŠ¤íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” OCR ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‘ì—… ìˆœì„œ

### 1ë‹¨ê³„: ì „ì²´ ë¬¸ì„œì—ì„œ ë‹¨ì¼ ê°’ í•„ë“œ ìŠ¤ìº”
ë¨¼ì € ë¬¸ì„œ ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë“¤ì²˜ëŸ¼ ì£¼ë¡œ í•œ ë²ˆë§Œ ë‚˜íƒ€ë‚˜ëŠ” ê°’ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤:
- "ì„±ëª…", "ìƒë…„ì›”ì¼", "ì•ˆë‚´ìœ í˜•", "ê¸°ì¥ì˜ë¬´"
- "ì¤‘ê°„ì˜ˆë‚©ì„¸ì•¡", "ì›ì²œì§•ìˆ˜ì„¸ì•¡"
- "êµ­ë¯¼ì—°ê¸ˆë³´í—˜ë£Œ", "ê°œì¸ì—°ê¸ˆì €ì¶•", "ì†Œê¸°ì—…ì†Œìƒê³µì¸ê³µì œë¶€ê¸ˆ (ë…¸ë€ìš°ì‚°ê³µì œ)" ë“±

### 2ë‹¨ê³„: ì‚¬ì—…ì†Œë“ í‘œì˜ ëª¨ë“  í–‰ ì°¾ê¸°
'ì‚¬ì—…ì¥ë³„ ìˆ˜ì…ê¸ˆì•¡' ë˜ëŠ” ìœ ì‚¬í•œ í‘œì—ì„œ **ëª¨ë“  í–‰(ë°ì´í„°)ì„ ì°¾ì•„ì£¼ì„¸ìš”**. 
- ê° í–‰ì€ í•˜ë‚˜ì˜ ì‚¬ì—…ì†Œë“ í•­ëª©ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
- **ë¹ˆ í–‰ì´ë‚˜ ëˆ„ë½ëœ í–‰ì´ ì—†ë„ë¡ ì£¼ì˜ê¹Šê²Œ í™•ì¸í•´ì£¼ì„¸ìš”**
- ë‹¤ìŒ í•„ë“œë“¤ì„ ê° í–‰ì—ì„œ ì¶”ì¶œ: "ì‚¬ì—…ì ë“±ë¡ë²ˆí˜¸", "ìƒí˜¸", "ìˆ˜ì…ì¢…ë¥˜ êµ¬ë¶„ì½”ë“œ", "ì—…ì¢… ì½”ë“œ", "ìˆ˜ì…ê¸ˆì•¡", "ê²½ë¹„ìœ¨" ë“±

### 3ë‹¨ê³„: ê° í–‰ë³„ JSON ê°ì²´ ìƒì„±
**ì‚¬ì—…ì†Œë“ í‘œì˜ ê° í–‰ë§ˆë‹¤** ë³„ë„ì˜ JSON ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:
1. í•´ë‹¹ í–‰ì˜ ì‚¬ì—… ê´€ë ¨ ë°ì´í„°ë¡œ ê°ì²´ë¥¼ ì±„ì›ë‹ˆë‹¤
2. **1ë‹¨ê³„ì—ì„œ ì°¾ì€ ëª¨ë“  ê³µí†µ ë°ì´í„°(ì„±ëª…, ìƒë…„ì›”ì¼ ë“±)ë¥¼ ë™ì¼í•˜ê²Œ ë³µì‚¬í•©ë‹ˆë‹¤**

### 4ë‹¨ê³„: ì™„ì „í•œ JSON ë°°ì—´ ìƒì„±
- **ëª¨ë“  ì‚¬ì—…ì†Œë“ í–‰ì´ í¬í•¨ë˜ë„ë¡ í™•ì¸**
- ê° ê°ì²´ëŠ” ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•¨
- ê°’ì´ ì—†ëŠ” í•„ë“œëŠ” "N/A" ë˜ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •

## ì¤‘ìš” ì§€ì¹¨
- **ì ˆëŒ€ë¡œ ë°ì´í„°ë¥¼ ëˆ„ë½í•˜ì§€ ë§ˆì„¸ìš”**
- **ëª¨ë“  ì‚¬ì—…ì†Œë“ í–‰ì„ ì°¾ì•„ ê°ê° ë³„ë„ì˜ JSON ê°ì²´ë¡œ ë§Œë“œì„¸ìš”**
- í•˜ë‚˜ì˜ ë¬¸ì„œì— ì—¬ëŸ¬ ì‚¬ì—…ì†Œë“ì´ ìˆë‹¤ë©´, ê·¸ ìˆ˜ë§Œí¼ JSON ê°ì²´ê°€ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤

### ì¶”ì¶œí•  í•­ëª©
{', '.join(EXTRACTION_FIELDS)}

### ì¶œë ¥ í˜•ì‹ (ì—¬ëŸ¬ í–‰ì´ ìˆì„ ê²½ìš°ì˜ ì˜ˆì‹œ)
{json_example}

**ë°˜ë“œì‹œ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.**
"""

# --- ğŸ’° ìˆ«ì ì •ì œ ëŒ€ìƒ í•„ë“œ ---
currency_fields = [
    "ì¤‘ê°„ì˜ˆë‚©ì„¸ì•¡", "ì›ì²œì§•ìˆ˜ì„¸ì•¡", "êµ­ë¯¼ì—°ê¸ˆë³´í—˜ë£Œ", "ê°œì¸ì—°ê¸ˆì €ì¶•",
    "ì†Œê¸°ì—…ì†Œìƒê³µì¸ê³µì œë¶€ê¸ˆ (ë…¸ë€ìš°ì‚°ê³µì œ)", "í‡´ì§ì—°ê¸ˆì„¸ì•¡ê³µì œ", "ì—°ê¸ˆê³„ì¢Œì„¸ì•¡ê³µì œ", "ìˆ˜ì…ê¸ˆì•¡"
]

# --- ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def clean_currency(value: str) -> str:
    if not isinstance(value, str): return "0"
    if value.strip() in ["", "ì—†ìŒ", "N/A"]: return "0"
    cleaned = re.sub(r"[^\d]", "", value)
    return cleaned if cleaned else "0"

def safe_extract_json(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ JSON ë°°ì—´ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ JSON ì°¾ê¸° ì‹œë„
    patterns = [
        r'\[[\s\S]*?\]',  # JSON ë°°ì—´ (ê°€ì¥ ìš°ì„ )
        r'```json\s*([\s\S]*?)\s*```',  # ë§ˆí¬ë‹¤ìš´ JSON ë¸”ë¡
        r'```\s*([\s\S]*?)\s*```',  # ì¼ë°˜ ë§ˆí¬ë‹¤ìš´ ë¸”ë¡
        r'\{[\s\S]*?\}',  # JSON ê°ì²´ (ë‹¨ì¼)
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.DOTALL)
        for match in matches:
            try:
                # ë§ˆí¬ë‹¤ìš´ íŒ¨í„´ì˜ ê²½ìš°
                if '```' in pattern and isinstance(match, str):
                    json_data = json.loads(match.strip())
                else:
                    json_data = json.loads(match)
                
                # ë°°ì—´ì´ ì•„ë‹Œ ê²½ìš° ë°°ì—´ë¡œ ë³€í™˜
                if isinstance(json_data, dict):
                    return [json_data]
                elif isinstance(json_data, list):
                    return json_data
                    
            except json.JSONDecodeError:
                continue
    
    return None

def extract_data_with_gemini(file_path: str, prompt: str):
    """
    Google Generative AI SDKë¥¼ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print(f"\nğŸ“„ '{os.path.basename(file_path)}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"ì˜¤ë¥˜: PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {file_path}")

    uploaded_file = None
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            print(f"ğŸ”„ ì‹œë„ {attempt + 1}/{max_retries}")
            
            # 1. File APIë¥¼ ì‚¬ìš©í•´ íŒŒì¼ ì—…ë¡œë“œ
            print("â˜ï¸ File APIë¡œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤...")
            uploaded_file = genai.upload_file(path=file_path, display_name=os.path.basename(file_path))
            
            # 2. ëª¨ë¸ ì´ˆê¸°í™” ë° ì½˜í…ì¸  ìƒì„± ìš”ì²­
            model = genai.GenerativeModel(model_name="gemini-2.5-flash")
            
            print("ğŸ§  Geminiì—ê²Œ ë°ì´í„° ì¶”ì¶œì„ ìš”ì²­í•©ë‹ˆë‹¤...")
            response = model.generate_content([uploaded_file, prompt])
            
            print(f"ğŸ“ ì‘ë‹µ ë°›ìŒ (ì‹œë„ {attempt + 1}/{max_retries})")
            print(f"ì‘ë‹µ ê¸¸ì´: {len(response.text)} ë¬¸ì")
            
            # 3. ì•ˆì „í•œ JSON ì¶”ì¶œ
            extracted_data = safe_extract_json(response.text)
            
            if extracted_data is None:
                print(f"âš ï¸ ì‹œë„ {attempt + 1}: JSON ì¶”ì¶œ ì‹¤íŒ¨")
                print(f"ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response.text[:500]}...")
                if attempt < max_retries - 1:
                    continue
                else:
                    raise ValueError(f"ëª¨ë“  ì‹œë„ì—ì„œ JSON ì¶”ì¶œ ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:\n{response.text}")
            
            print(f"âœ… ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ. {len(extracted_data)}ê°œ í•­ëª© ë°œê²¬")
            return extracted_data
            
        except Exception as e:
            print(f"âŒ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt == max_retries - 1:
                raise
        finally:
            # 4. ì²˜ë¦¬ í›„ ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
            if uploaded_file:
                try:
                    print(f"ğŸ—‘ï¸ ì—…ë¡œë“œëœ íŒŒì¼ '{uploaded_file.display_name}'ì„ ì‚­ì œí•©ë‹ˆë‹¤.")
                    genai.delete_file(uploaded_file.name)
                    uploaded_file = None
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")

def validate_and_fix_data(data_list):
    """
    ì¶”ì¶œëœ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ìˆ˜ì •
    """
    if not isinstance(data_list, list):
        print("âš ï¸ ë°ì´í„°ê°€ ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤. ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        return [data_list] if isinstance(data_list, dict) else []
    
    validated_data = []
    for i, item in enumerate(data_list):
        if not isinstance(item, dict):
            print(f"âš ï¸ í•­ëª© {i+1}ì´ ê°ì²´ê°€ ì•„ë‹™ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        # ëª¨ë“  í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
        for field in EXTRACTION_FIELDS:
            if field not in item:
                item[field] = "N/A"
        
        validated_data.append(item)
    
    print(f"âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ. {len(validated_data)}ê°œ í•­ëª© ìœ íš¨")
    return validated_data

# --- ğŸš€ Main ---
def main():
    print("--- ğŸš€ PDF ì¼ê´„ ì²˜ë¦¬ ë° ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì…ë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")

    # --- Google API ì¸ì¦ (Gemini ë° Sheets) ---
    try:
        # Gemini API ì´ˆê¸°í™”
        if not API_KEY:
            raise ValueError("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        genai.configure(api_key=API_KEY)
        print("âœ… Gemini API ì´ˆê¸°í™” ì„±ê³µ!")

        # Google Sheets ì¸ì¦
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)
        client = gspread.authorize(creds)
        spreadsheet = client.open(SPREADSHEET_NAME)
        worksheet = spreadsheet.sheet1
        
        # ì˜¤ë¥˜ ë¡œê·¸ ì‹œíŠ¸ ì„¤ì •
        try:
            log_worksheet = spreadsheet.worksheet("ì˜¤ë¥˜_ë¡œê·¸")
        except gspread.exceptions.WorksheetNotFound:
            log_worksheet = spreadsheet.add_worksheet(title="ì˜¤ë¥˜_ë¡œê·¸", rows="100", cols="10")
            log_worksheet.append_row(["íŒŒì¼ ì´ë¦„", "ì˜¤ë¥˜ ë‚´ìš©", "ì²˜ë¦¬ ì‹œê°„"])
        
        print("âœ… êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ê²° ì„±ê³µ!")
    except Exception as e:
        print(f"\nâŒ êµ¬ê¸€ API ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # í—¤ë” ì„¤ì •
    try:
        first_row = worksheet.row_values(1)
        if not first_row:
            print("ğŸ“ 1í–‰ì´ ë¹„ì–´ìˆì–´ í—¤ë”ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤...")
            headers = ["íŒŒì¼ì´ë¦„", "í–‰ë²ˆí˜¸"] + EXTRACTION_FIELDS
            worksheet.append_row(headers)
        else:
            print("ğŸ“ í—¤ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ í—¤ë” í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    try:
        pdf_files = [f for f in os.listdir(PDF_FOLDER_PATH) if f.lower().endswith('.pdf')]
        if not pdf_files:
            print(f"âŒ '{PDF_FOLDER_PATH}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        print(f"\nğŸ“‚ ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤: {pdf_files}")
    except FileNotFoundError:
        print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{PDF_FOLDER_PATH}'")
        return

    total_rows_added = 0
    error_count = 0

    # ê° PDF íŒŒì¼ ì²˜ë¦¬
    for pdf_file in pdf_files:
        try:
            full_path = os.path.join(PDF_FOLDER_PATH, pdf_file)
            print(f"\nğŸ”„ '{pdf_file}' ì²˜ë¦¬ ì¤‘...")
            
            # ë°ì´í„° ì¶”ì¶œ
            extracted_data_list = extract_data_with_gemini(full_path, GEMINI_PROMPT)
            
            # ë°ì´í„° ê²€ì¦ ë° ìˆ˜ì •
            validated_data = validate_and_fix_data(extracted_data_list)
            
            if not validated_data:
                print(f"âš ï¸ '{pdf_file}'ì—ì„œ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                import datetime
                log_worksheet.append_row([pdf_file, "ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ", datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")])
                continue
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì¶”ê°€í•  í–‰ë“¤ ì¤€ë¹„
            rows_to_append = []
            for i, extracted_data in enumerate(validated_data):
                # ì²« ë²ˆì§¸ í–‰ì—ë§Œ íŒŒì¼ ì´ë¦„ í‘œì‹œ, ë‚˜ë¨¸ì§€ëŠ” ë¹ˆ ë¬¸ìì—´
                file_name_to_log = pdf_file if i == 0 else ""
                row_number = i + 1
                
                data_row = [file_name_to_log, row_number]
                for field in EXTRACTION_FIELDS:
                    value = extracted_data.get(field, 'N/A')
                    if isinstance(value, str):
                        value = value.replace('\n', ' ').replace('\r', ' ')
                    if field in currency_fields:
                        value = clean_currency(str(value))
                    data_row.append(str(value))
                
                rows_to_append.append(data_row)
            
            # í•œ ë²ˆì— ëª¨ë“  í–‰ ì¶”ê°€ (íš¨ìœ¨ì„± ì¦ëŒ€)
            if rows_to_append:
                worksheet.append_rows(rows_to_append)
                total_rows_added += len(rows_to_append)
            
            print(f"âœ… '{pdf_file}' ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ğŸ“Š ì¶”ì¶œëœ ë°ì´í„°: {len(validated_data)}ê°œ í•­ëª©")
            print(f"   ğŸ“ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì¶”ê°€: {len(rows_to_append)}ê°œ í–‰")

        except Exception as e:
            error_message = f"ğŸš¨ '{pdf_file}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            print(error_message)
            
            # ì˜¤ë¥˜ ë¡œê·¸ì— ê¸°ë¡
            import datetime
            log_worksheet.append_row([pdf_file, str(e), datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")])
            error_count += 1
            continue

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n--- âœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ---")
    print(f"ğŸ“Š ì´ ì²˜ë¦¬ëœ íŒŒì¼: {len(pdf_files)}ê°œ")
    print(f"âœ… ì„±ê³µ: {len(pdf_files) - error_count}ê°œ")
    print(f"âŒ ì˜¤ë¥˜: {error_count}ê°œ")
    print(f"ğŸ“ ì´ ì¶”ê°€ëœ í–‰: {total_rows_added}ê°œ")
    
    if error_count > 0:
        print(f"ğŸ” ì˜¤ë¥˜ ìƒì„¸ ë‚´ìš©ì€ 'ì˜¤ë¥˜_ë¡œê·¸' ì‹œíŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == '__main__':
    main()